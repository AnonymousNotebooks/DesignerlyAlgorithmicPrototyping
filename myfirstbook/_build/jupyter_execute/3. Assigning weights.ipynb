{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cce2977",
   "metadata": {},
   "source": [
    "# 3. Assigning weights\n",
    "\n",
    "Once we have identified meaningful patterns in the data, we can use them to assign weights to the relevant value counts to inform the predictions. For instance, we can use the amount of times a household bought groceries on a Monday as a weight that influences the probability that the algorithm will predict Monday as a potential grocery day (e.g., if they bought groceires on Monday one time out of eight, it is unlikely that the algorithm predicted that the household would buy groceries on Monday again)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a3a18",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242714e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "#Pandas is a software library written for the Python programming language for data manipulation and analysis.\n",
    "import pandas as pd\n",
    "#NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "import numpy as np\n",
    "# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.\n",
    "import matplotlib.pyplot as plt\n",
    "#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "from datetime import time\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from matplotlib.pyplot import figure\n",
    "class bcolors:\n",
    "    WARNING = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    \n",
    "SEED = 30\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963515aa",
   "metadata": {},
   "source": [
    "## 3.1. Days of the week\n",
    "\n",
    "\n",
    "Outcome (example):\n",
    "1. input: Monday,Tuesday...\n",
    "2. output: 0 times, 1 time, 2 times..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971f711",
   "metadata": {},
   "source": [
    "### Load and view data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b7130b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\20204113\\\\OneDrive - TU Eindhoven\\\\2_Research\\\\1_Groceries\\\\DATA\\\\9th week - narrative (3rd attempt)\\\\HH2\\\\df\\\\df_HH2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data for dow\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# df_period1 = pd.read_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_period1.csv\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# df_period2 = pd.read_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_period2.csv\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDAYS_HH2weights\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m period1, period2\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Function to define the limits for total visits, days, same store and type per week\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mAlgorithmCOUNTS_HH2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountTotalVisits, CountTotalDays, CountStoreName, CountTimePerDay, CountStoreType, CountTotalPerday, CountVisitsPerDay, CountTimingPerDay\n",
      "File \u001b[0;32m/workspaces/Plenty-in-the-Pantry/myfirstbook/DAYS_HH2weights.py:63\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chi2_contingency\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# ### Load and view data \u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# In[96]:\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m20204113\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive - TU Eindhoven\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2_Research\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m1_Groceries\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDATA\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m9th week - narrative (3rd attempt)\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mHH2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdf\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdf_HH2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# del df[\"HH\"]\u001b[39;00m\n\u001b[1;32m     66\u001b[0m df\u001b[38;5;241m.\u001b[39mdescribe(include\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plenty-in-the-pantry-xPFdo8rA-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plenty-in-the-pantry-xPFdo8rA-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plenty-in-the-pantry-xPFdo8rA-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plenty-in-the-pantry-xPFdo8rA-py3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/plenty-in-the-pantry-xPFdo8rA-py3.10/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\20204113\\\\OneDrive - TU Eindhoven\\\\2_Research\\\\1_Groceries\\\\DATA\\\\9th week - narrative (3rd attempt)\\\\HH2\\\\df\\\\df_HH2.csv'"
     ]
    }
   ],
   "source": [
    "  # data for dow\n",
    "# df_period1 = pd.read_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_period1.csv\")\n",
    "# df_period2 = pd.read_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_period2.csv\")\n",
    "from DAYS_HH2weights import period1, period2\n",
    "\n",
    "  #Function to define the limits for total visits, days, same store and type per week\n",
    "from AlgorithmCOUNTS_HH2 import CountTotalVisits, CountTotalDays, CountStoreName, CountTimePerDay, CountStoreType, CountTotalPerday, CountVisitsPerDay, CountTimingPerDay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf4c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>day</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>sum</th>\n",
       "      <th>ndays</th>\n",
       "      <th>med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "day  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday  Sunday  sum  \\\n",
       "0       0.0      2.0        1.0       0.0     1.0       0.0     0.0  4.0   \n",
       "1       0.0      0.0        2.0       2.0     0.0       0.0     3.0  7.0   \n",
       "2       0.0      0.0        0.0       1.0     1.0       1.0     2.0  5.0   \n",
       "3       0.0      0.0        1.0       0.0     0.0       1.0     3.0  5.0   \n",
       "4       2.0      2.0        0.0       0.0     0.0       3.0     0.0  7.0   \n",
       "5       0.0      1.0        0.0       0.0     0.0       1.0     1.0  3.0   \n",
       "6       1.0      0.0        0.0       1.0     0.0       1.0     0.0  3.0   \n",
       "7       2.0      0.0        1.0       1.0     1.0       0.0     0.0  5.0   \n",
       "\n",
       "day  ndays  med  \n",
       "0        3  1.0  \n",
       "1        3  2.0  \n",
       "2        4  1.0  \n",
       "3        3  1.0  \n",
       "4        3  2.0  \n",
       "5        3  1.0  \n",
       "6        3  1.0  \n",
       "7        4  1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_period1 = pd.concat([period1(), period2()])\n",
    "df_period1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189329e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights based on how the numbers per day are represented\n",
    "df_Mondays1 = pd.DataFrame(df_period1['Monday'])\n",
    "df_Mondays1['weights'] = df_Mondays1.groupby(['Monday'])['Monday'].transform('count')\n",
    "df_Mondays1 = df_Mondays1.drop_duplicates()\n",
    "\n",
    "df_Tuesdays1 = pd.DataFrame(df_period1['Tuesday'])\n",
    "df_Tuesdays1['weights'] = df_Tuesdays1.groupby(['Tuesday'])['Tuesday'].transform('count')\n",
    "df_Tuesdays1 = df_Tuesdays1.drop_duplicates()\n",
    "\n",
    "df_Wednesdays1 = pd.DataFrame(df_period1['Wednesday'])\n",
    "df_Wednesdays1['weights'] = df_Wednesdays1.groupby(['Wednesday'])['Wednesday'].transform('count')\n",
    "df_Wednesdays1 = df_Wednesdays1.drop_duplicates()\n",
    "\n",
    "df_Thursdays1 = pd.DataFrame(df_period1['Thursday'])\n",
    "df_Thursdays1['weights'] = df_Thursdays1.groupby(['Thursday'])['Thursday'].transform('count')\n",
    "df_Thursdays1 = df_Thursdays1.drop_duplicates()\n",
    "\n",
    "df_Fridays1 = pd.DataFrame(df_period1['Friday'])\n",
    "df_Fridays1['weights'] = df_Fridays1.groupby(['Friday'])['Friday'].transform('count')\n",
    "df_Fridays1 = df_Fridays1.drop_duplicates()\n",
    "\n",
    "df_Saturdays1 = pd.DataFrame(df_period1['Saturday'])\n",
    "df_Saturdays1['weights'] = df_Saturdays1.groupby(['Saturday'])['Saturday'].transform('count')\n",
    "df_Saturdays1 = df_Saturdays1.drop_duplicates()\n",
    "\n",
    "df_Sundays1 = pd.DataFrame(df_period1['Sunday'])\n",
    "df_Sundays1['weights'] = df_Sundays1.groupby(['Sunday'])['Sunday'].transform('count')\n",
    "df_Sundays1 = df_Sundays1.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_period2 = pd.concat([period1(), period2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e412728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights based on how the numbers per day are represented\n",
    "df_Mondays2 = pd.DataFrame(df_period2['Monday'])\n",
    "df_Mondays2['weights'] = df_Mondays2.groupby(['Monday'])['Monday'].transform('count')\n",
    "df_Mondays2 = df_Mondays2.drop_duplicates()\n",
    "\n",
    "df_Tuesdays2 = pd.DataFrame(df_period2['Tuesday'])\n",
    "df_Tuesdays2['weights'] = df_Tuesdays2.groupby(['Tuesday'])['Tuesday'].transform('count')\n",
    "df_Tuesdays2 = df_Tuesdays2.drop_duplicates()\n",
    "\n",
    "df_Wednesdays2 = pd.DataFrame(df_period2['Wednesday'])\n",
    "df_Wednesdays2['weights'] = df_Wednesdays2.groupby(['Wednesday'])['Wednesday'].transform('count')\n",
    "df_Wednesdays2 = df_Wednesdays2.drop_duplicates()\n",
    "\n",
    "df_Thursdays2 = pd.DataFrame(df_period2['Thursday'])\n",
    "df_Thursdays2['weights'] = df_Thursdays2.groupby(['Thursday'])['Thursday'].transform('count')\n",
    "df_Thursdays2 = df_Thursdays2.drop_duplicates()\n",
    "\n",
    "df_Fridays2 = pd.DataFrame(df_period2['Friday'])\n",
    "df_Fridays2['weights'] = df_Fridays2.groupby(['Friday'])['Friday'].transform('count')\n",
    "df_Fridays2 = df_Fridays2.drop_duplicates()\n",
    "\n",
    "df_Saturdays2 = pd.DataFrame(df_period2['Saturday'])\n",
    "df_Saturdays2['weights'] = df_Saturdays2.groupby(['Saturday'])['Saturday'].transform('count')\n",
    "df_Saturdays2 = df_Saturdays2.drop_duplicates()\n",
    "\n",
    "df_Sundays2 = pd.DataFrame(df_period2['Sunday'])\n",
    "df_Sundays2['weights'] = df_Sundays2.groupby(['Sunday'])['Sunday'].transform('count')\n",
    "df_Sundays2 = df_Sundays2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728e392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunday</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunday  weights\n",
       "0     0.0        4\n",
       "5     1.0        1\n",
       "2     2.0        1\n",
       "1     3.0        2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df_Thursdays1.sort_values(by=['Thursday'])\n",
    "# df_Fridays1.sort_values(by=['Friday'])\n",
    "# df_Saturdays1.sort_values(by=['Saturday'])\n",
    "df_Sundays1.sort_values(by=['Sunday'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c308b45d",
   "metadata": {},
   "source": [
    "## 3.2. Store types/names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one day\n",
    "Monday = 'Monday'\n",
    "Tuesday = 'Tuesday'\n",
    "Wednesday = 'Wednesday'\n",
    "Thursday = 'Thursday'\n",
    "Friday = 'Friday'\n",
    "Saturday = 'Saturday'\n",
    "Sunday = 'Sunday'\n",
    "\n",
    "# select only these data for the df\n",
    "df_Monday = df[df['day'] == 'Monday']\n",
    "df_Tuesday = df[df['day'] == 'Tuesday']\n",
    "df_Wednesday = df[df['day'] == 'Wednesday']\n",
    "df_Thursday = df[df['day'] == 'Thursday']\n",
    "df_Friday = df[df['day'] == 'Friday']\n",
    "df_Saturday = df[df['day'] == 'Saturday']\n",
    "df_Sunday = df[df['day'] == 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Mo = df_Monday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Mo = pd.DataFrame (df_Mo)\n",
    "df_Mo = df_Mo.reset_index()\n",
    "df_Mo = df_Mo.loc[~(df_Mo==0).any(axis=1)]\n",
    "df_Mo = df_Mo.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_Tu = df_Tuesday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Tu = pd.DataFrame (df_Tu)\n",
    "df_Tu = df_Tu.reset_index()\n",
    "df_Tu = df_Tu.loc[~(df_Tu==0).any(axis=1)]\n",
    "df_Tu = df_Tu.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_We = df_Wednesday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_We = pd.DataFrame (df_We)\n",
    "df_We = df_We.reset_index()\n",
    "df_We = df_We.loc[~(df_We==0).any(axis=1)]\n",
    "df_We = df_We.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_Th = df_Thursday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Th = pd.DataFrame (df_Th)\n",
    "df_Th = df_Th.reset_index()\n",
    "df_Th = df_Th.loc[~(df_Th==0).any(axis=1)]\n",
    "df_Th = df_Th.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_Fr = df_Friday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Fr = pd.DataFrame (df_Fr)\n",
    "df_Fr = df_Fr.reset_index()\n",
    "df_Fr = df_Fr.loc[~(df_Fr==0).any(axis=1)]\n",
    "df_Fr = df_Fr.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_Sa = df_Saturday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Sa = pd.DataFrame (df_Sa)\n",
    "df_Sa = df_Sa.reset_index()\n",
    "df_Sa = df_Sa.loc[~(df_Sa==0).any(axis=1)]\n",
    "df_Sa = df_Sa.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_Su = df_Sunday.groupby(['store_name', 'store_type'])['order_ID'].nunique()\n",
    "df_Su = pd.DataFrame (df_Su)\n",
    "df_Su = df_Su.reset_index()\n",
    "df_Su = df_Su.loc[~(df_Su==0).any(axis=1)]\n",
    "df_Su = df_Su.rename(columns={\"order_ID\": \"weight\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Mo.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Mo.csv\", index = None, header=True)\n",
    "df_Tu.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Tu.csv\", index = None, header=True)\n",
    "df_We.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_We.csv\", index = None, header=True)\n",
    "df_Th.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Th.csv\", index = None, header=True)\n",
    "df_Fr.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Fr.csv\", index = None, header=True)\n",
    "df_Sa.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Sa.csv\", index = None, header=True)\n",
    "df_Su.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_Su.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572a468",
   "metadata": {},
   "source": [
    "## 3.3. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b7f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19722/711048548.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_orders['time'] = df_orders['time'].replace(['afternoon', 'evening'], 'afternoon')\n"
     ]
    }
   ],
   "source": [
    "# aggregate afternoon and evening\n",
    "df_orders['time'] = df_orders['time'].replace(['afternoon', 'evening'], 'afternoon')\n",
    "\n",
    "# to select only one\n",
    "store1 = 'Albert Heijn'\n",
    "store2 = 'Sys'\n",
    "store3 = 'Okay'\n",
    "store4 = 'Delhaize'\n",
    "store5 = 'Versavel Poelman'\n",
    "store6 = 'Kruidvat'\n",
    "store7 = 'Brabo'\n",
    "store8 = 'Ikea'\n",
    "store9 = 'Carrefour'\n",
    "\n",
    "# select only these data for the df\n",
    "df_store1 = df_orders[df_orders['store_name'] == store1]\n",
    "df_store2 = df_orders[df_orders['store_name'] == store2]\n",
    "df_store3 = df_orders[df_orders['store_name'] == store3]\n",
    "df_store4 = df_orders[df_orders['store_name'] == store4]\n",
    "df_store5 = df_orders[df_orders['store_name'] == store5]\n",
    "df_store6 = df_orders[df_orders['store_name'] == store6]\n",
    "df_store7 = df_orders[df_orders['store_name'] == store7]\n",
    "df_store8 = df_orders[df_orders['store_name'] == store8]\n",
    "df_store9 = df_orders[df_orders['store_name'] == store9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbeca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AH = df_store1.groupby(['time'])['order_ID'].nunique()\n",
    "df_AH = pd.DataFrame (df_AH)\n",
    "df_AH = df_AH.reset_index()\n",
    "df_AH = df_AH.loc[~(df_AH==0).any(axis=1)]\n",
    "df_AH = df_AH.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_SYS = df_store2.groupby(['time'])['order_ID'].nunique()\n",
    "df_SYS= pd.DataFrame (df_SYS)\n",
    "df_SYS = df_SYS.reset_index()\n",
    "df_SYS = df_SYS.loc[~(df_SYS==0).any(axis=1)]\n",
    "df_SYS = df_SYS.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_OKAY = df_store3.groupby(['time'])['order_ID'].nunique()\n",
    "df_OKAY = pd.DataFrame (df_OKAY)\n",
    "df_OKAY = df_OKAY.reset_index()\n",
    "df_OKAY = df_OKAY.loc[~(df_OKAY==0).any(axis=1)]\n",
    "df_OKAY = df_OKAY.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_DELHAIZE = df_store4.groupby(['time'])['order_ID'].nunique()\n",
    "df_DELHAIZE = pd.DataFrame (df_DELHAIZE)\n",
    "df_DELHAIZE = df_DELHAIZE.reset_index()\n",
    "df_DELHAIZE = df_DELHAIZE.loc[~(df_DELHAIZE==0).any(axis=1)]\n",
    "df_DELHAIZE = df_DELHAIZE.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_VERSAVEL = df_store5.groupby(['time'])['order_ID'].nunique()\n",
    "df_VERSAVEL = pd.DataFrame (df_VERSAVEL)\n",
    "df_VERSAVEL = df_VERSAVEL.reset_index()\n",
    "df_VERSAVEL = df_VERSAVEL.loc[~(df_VERSAVEL==0).any(axis=1)]\n",
    "df_VERSAVEL = df_VERSAVEL.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_KRUIDVAT = df_store6.groupby(['time'])['order_ID'].nunique()\n",
    "df_KRUIDVAT = pd.DataFrame (df_KRUIDVAT)\n",
    "df_KRUIDVAT = df_KRUIDVAT.reset_index()\n",
    "df_KRUIDVAT = df_KRUIDVAT.loc[~(df_KRUIDVAT==0).any(axis=1)]\n",
    "df_KRUIDVAT = df_KRUIDVAT.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_BRABO = df_store7.groupby(['time'])['order_ID'].nunique()\n",
    "df_BRABO = pd.DataFrame (df_BRABO)\n",
    "df_BRABO = df_BRABO.reset_index()\n",
    "df_BRABO = df_BRABO.loc[~(df_BRABO==0).any(axis=1)]\n",
    "df_BRABO = df_BRABO.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_IKEA = df_store8.groupby(['time'])['order_ID'].nunique()\n",
    "df_IKEA = pd.DataFrame (df_IKEA)\n",
    "df_IKEA = df_IKEA.reset_index()\n",
    "df_IKEA = df_IKEA.loc[~(df_IKEA==0).any(axis=1)]\n",
    "df_IKEA = df_IKEA.rename(columns={\"order_ID\": \"weight\"})\n",
    "\n",
    "df_CARREFOUR = df_store9.groupby(['time'])['order_ID'].nunique()\n",
    "df_CARREFOUR = pd.DataFrame (df_CARREFOUR)\n",
    "df_CARREFOUR = df_CARREFOUR.reset_index()\n",
    "df_CARREFOUR = df_CARREFOUR.loc[~(df_CARREFOUR==0).any(axis=1)]\n",
    "df_CARREFOUR = df_CARREFOUR.rename(columns={\"order_ID\": \"weight\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noon</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time  weight\n",
       "0  afternoon       1\n",
       "1    morning       3\n",
       "2       noon       7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_AH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f895d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AH.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_AHTime.csv\", index = None, header=True)\n",
    "df_SYS.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_SYTime.csv\", index = None, header=True)\n",
    "df_OKAY.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_OKTime.csv\", index = None, header=True)\n",
    "df_DELHAIZE.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_DETime.csv\", index = None, header=True)\n",
    "df_VERSAVEL.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_VETime.csv\", index = None, header=True)\n",
    "df_KRUIDVAT.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_KRTime.csv\", index = None, header=True)\n",
    "df_BRABO.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_BRTime.csv\", index = None, header=True)\n",
    "df_IKEA.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_IKTime.csv\", index = None, header=True)\n",
    "df_CARREFOUR.to_csv (r\"C:\\Users\\20204113\\OneDrive - TU Eindhoven\\2_Research\\1_Groceries\\DATA\\9th week - narrative (3rd attempt)\\HH2\\df\\df_HH2_CATime.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da13fae",
   "metadata": {},
   "source": [
    "## 3.4. Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43475b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (r\"/workspaces/Plenty-in-the-Pantry/database/Groceries_onehousehold1.csv\")\n",
    "\n",
    "df['weights_itemtype'] = df.groupby('item_type')['item_type'].transform('count')\n",
    "\n",
    "df.to_csv(r\"/workspaces/Plenty-in-the-Pantry/database/Groceries_onehousehold1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}